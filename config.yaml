model_name: distilgpt2
batch_size: 128
n_epochs: 8
text_crop: 0
model:
  embedding_dim: 64
  hidden_dim: 64
  n_layers: 1
  dropout: 0.5
  learning_rate: 0.002