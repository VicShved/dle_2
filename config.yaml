model_name: distilgpt2
batch_size: 256
n_epochs: 32
text_crop: 0
model:
  embedding_dim: 128
  hidden_dim: 128
  n_layers: 1
  dropout: 0.5
  learning_rate: 0.002